{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Best Picture Winners & Nominees\n",
    "*An Analysis by Sean Osier*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pickle\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.mpl_style = 'default'\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# For display\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickling functions\n",
    "def pickle_it(data, filename, python_version=3):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    data = the data you want to pickle (save)\n",
    "    filename = file name where you want to save the data\n",
    "    python_version = the python version where you will be opening the pickle file\n",
    "    \n",
    "    Out:\n",
    "    Saves a pickle file with your data to to the filename you specify\n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as picklefile:\n",
    "        pickle.dump(data, picklefile, protocol=python_version)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    filename = name of the pickle file you want to open (e.g \"my_pickle.pkl\")\n",
    "    \n",
    "    Out:\n",
    "    Opens and returns the content of the picklefile to a variable of your choice\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as picklefile: \n",
    "        return pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_IMDB_data(movie_data):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    movie_data = list of lists of raw movie data scraped from IMDB index list pages\n",
    "    \n",
    "    Out:\n",
    "    df = Pandas dataframe with the raw movie data cleaned and processed\n",
    "    \"\"\"\n",
    "    headers = [\"title\", \"year\", \"link\", \"user_rating_long\", \"user_rating_short\",\n",
    "                           \"outline\", \"director\", \"starring\", \"genre\", \"pg_rating\", \"runtime\"]\n",
    "    df = pd.DataFrame(movie_data, columns=headers)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Some initial cleaning\n",
    "    df[\"year\"] = df[\"year\"].replace(\"(2012 Documentary)\", \"(2012)\")\n",
    "    \n",
    "    # Key\n",
    "    df[\"key\"] = df[\"title\"] + \" \" + df[\"year\"]\n",
    "    \n",
    "    # Year\n",
    "    df[\"year\"] = df[\"year\"].apply(lambda x: x[1:-1])\n",
    "    \n",
    "    # Link\n",
    "    df[\"link\"] = \"http://www.imdb.com\" + df[\"link\"]\n",
    "    \n",
    "    # User Rating\n",
    "    df[\"user_rating_short\"] = df[\"user_rating_short\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # User Rating n-size\n",
    "    df[\"user_rating_n\"] = df[\"user_rating_long\"].apply(lambda x: x.split()[4] if x != \"\" else \"\")\n",
    "    df[\"user_rating_n\"] = df[\"user_rating_n\"].apply(lambda x: x[1:].replace(\",\", \"\") if x != \"\" else \"\")\n",
    "    df[\"user_rating_n\"] = df[\"user_rating_n\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # Director(s)\n",
    "    df[\"director\"] = df[\"director\"].apply(lambda x: x.split(\", \"))\n",
    "    \n",
    "    # Lead Actors\n",
    "    df[\"starring\"] = df[\"starring\"].apply(lambda x: x.split(\", \"))\n",
    "    \n",
    "    # Genre\n",
    "    df[\"genre\"] = df[\"genre\"].apply(lambda x: x.split(\" | \"))\n",
    "    \n",
    "    # Runtime\n",
    "    df[\"runtime\"] = df[\"runtime\"].apply(lambda x: x.split()[0] if x != \"\" else \"\")\n",
    "    df[\"runtime\"] = df[\"runtime\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # Removed unneed columns\n",
    "    df = df[[\"key\", \"title\", \"year\", \"user_rating_short\", \"user_rating_n\", \"director\", \"starring\", \"genre\", \\\n",
    "            \"runtime\", \"pg_rating\", \"link\"]]\n",
    "    \n",
    "    # More cleaning\n",
    "    df = df[(df[\"year\"] != \"2015\") & (df[\"year\"] != \"2016\") & (df[\"year\"] != \"????\") & (df[\"year\"] != \"???? \")]\n",
    "    keep_criterion = df[\"runtime\"].map(lambda x: ((x >= 45) and (x <= 360)) or (pd.isnull(x)))\n",
    "    df = df[keep_criterion]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_nominee_and_winner_data(data):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    data = list of lists of raw Best Picture winner and nominee data scraped from Wikipedia\n",
    "    \n",
    "    Out:\n",
    "    df = Pandas dataframe with the raw Best Picture status data cleaned and processed\n",
    "    \"\"\"\n",
    "    headers = [\"title\", \"year\", \"status\"]\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Initial cleaning\n",
    "    df[\"title\"] = df[\"title\"].replace(\"The Godfather Part III\", \"The Godfather: Part III\")\n",
    "    df[\"title\"] = df[\"title\"].replace(\"Good Night, and Good Luck\", \"Good Night, and Good Luck.\")\n",
    "    df[\"title\"] = df[\"title\"].replace(\"Precious: Based on the Novel \\\"Push\\\" by Sapphire\", \"Precious\")\n",
    "    df[\"title\"] = df[\"title\"].replace(\"Extremely Loud and Incredibly Close\", \"Extremely Loud & Incredibly Close\")\n",
    "    df[\"title\"] = df[\"title\"].replace(\"Birdman or (The Unexpected Virtue of Ignorance)\", \n",
    "                                      \"Birdman: Or (The Unexpected Virtue of Ignorance)\")\n",
    "    \n",
    "    # Key\n",
    "    df[\"key\"] = df[\"title\"] + \" (\" + df[\"year\"] + \")\"\n",
    "    \n",
    "    # Status Year (Year Nominated For)\n",
    "    df[\"status_year\"] = df[\"year\"]\n",
    "    \n",
    "    df = df[[\"key\", \"title\", \"year\", \"status\", \"status_year\"]]\n",
    "    \n",
    "    # More cleaning\n",
    "    df[\"key\"] = df[\"key\"].replace(\"Il Postino: The Postman (1995)\", \"Il Postino: The Postman (1994)\")\n",
    "    df[\"key\"] = df[\"key\"].replace(\"Life Is Beautiful (1998)\", \"Life Is Beautiful (1997)\")\n",
    "    df[\"key\"] = df[\"key\"].replace(\"Crash (2005)\", \"Crash (2004)\")\n",
    "    df[\"key\"] = df[\"key\"].replace(\"The Hurt Locker (2009)\", \"The Hurt Locker (2008)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_color(color_list):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    color_list = raw list of colors scraped from individula IMDB movie pages\n",
    "    \n",
    "    Out:\n",
    "    colors = cleaned and processed list of colors\n",
    "    \"\"\"\n",
    "    colors = []\n",
    "    for color in color_list:\n",
    "        if (\"Color\" in color) or (\"color\" in color):\n",
    "            colors.append(\"Color\")\n",
    "        if (\"Black\" in color) or (\"White\" in color) or (\"B&W\" in color):\n",
    "            colors.append(\"Black and White\")\n",
    "    \n",
    "    colors = list(set(colors))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_division_string(s):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    s = mathmatical string with division (e.g. \"12 / 24\" or \"1 / 2 / 3\")\n",
    "    \n",
    "    Out:\n",
    "    result = float of the what s evaluates to \n",
    "    \"\"\"\n",
    "    numbers = s.split(\"/\")\n",
    "    result = \"\"\n",
    "    for i, n in enumerate(numbers):\n",
    "        if i == 0:\n",
    "            result = float(n)\n",
    "        else:\n",
    "            result /= float(n)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_numbers(s):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    s = a string\n",
    "    \n",
    "    Out:\n",
    "    A string with all numbers removed\n",
    "    \"\"\"\n",
    "    return \"\".join([c for c in s if c not in string.digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load exchanges rates data\n",
    "exchange_rates = load_pickle(\"exchange_rates.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_USD(n, currency):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    n = an amount of money\n",
    "    currency = the currency of n\n",
    "    \n",
    "    Out:\n",
    "    n in US dollars ($)\n",
    "    \"\"\"\n",
    "    return n*exchange_rates[currency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_detailed_movie_data(data):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    data = raw detailed movie data scraped from individual IMDB movie pages\n",
    "    \n",
    "    Out:\n",
    "    df = Pandas dataframe with the raw detailed movie data processed and cleaned\n",
    "    \"\"\"\n",
    "    headers = [\"link\", \"release_date\", \"critic_rating\", \"critic_rating_n\", \"writer\", \"country\", \"language\", \\\n",
    "            \"budget\", \"opening_weekend_gross\", \"production_company\", \"sound_mix\", \"color\", \"aspect_ratio\"]\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    # Release date\n",
    "    df[\"release_date_details\"] = df[\"release_date\"].apply(lambda x: len(x.split()))\n",
    "    default = datetime.datetime(1000, 1, 1)\n",
    "    df[\"release_date_datetime\"] = df[\"release_date\"].apply(lambda x: dateutil.parser.parse(x, default=default))\n",
    "    df[\"release_month\"] = df[df[\"release_date_details\"] >= 2][\"release_date_datetime\"].apply(lambda x: x.month)\n",
    "    df[\"release_day_in_year\"] = df[df[\"release_date_details\"] >= 3][\"release_date_datetime\"].apply( \\\n",
    "        lambda x: x.timetuple().tm_yday)\n",
    "    \n",
    "    # Critic rating\n",
    "    df[\"critic_rating\"] = df[\"critic_rating\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # Budget\n",
    "    df[\"budget\"] = df[\"budget\"].apply(lambda x: x.replace(\",\", \"\"))\n",
    "    df[\"budget_currency\"] = df[\"budget\"].apply(lambda x: remove_numbers(x.split()[0]) if x != \"\" else x)\n",
    "    df[\"budget_currency\"] = df[\"budget_currency\"].replace(\"$\", \"USD\")\n",
    "    df[\"budget_currency\"] = df[\"budget_currency\"].replace(\"£\", \"GBP\")\n",
    "    df[\"budget_currency\"] = df[\"budget_currency\"].replace(\"€\", \"EUR\")\n",
    "    df[\"budget_currency\"] = df[\"budget_currency\"].replace(\"€.\", \"EUR\")\n",
    "    df[\"budget_USD\"] = df[\"budget\"].apply(lambda x: float(x[1:].split()[-1]) if x != \"\" else x)\n",
    "    df[\"budget_USD\"] = df.apply(lambda x: convert_to_USD(x[\"budget_USD\"], x[\"budget_currency\"]) \n",
    "                                if x[\"budget_USD\"] != \"\" else \"\", axis=1)\n",
    "    \n",
    "    # Gross\n",
    "    df[\"opening_weekend_gross\"] = df[\"opening_weekend_gross\"].apply(lambda x: x.replace(\",\", \"\"))\n",
    "    df[\"opening_weekend_gross_currency\"] = df[\"opening_weekend_gross\"].apply(lambda x: remove_numbers(x.split()[0]) \n",
    "                                                                             if x != \"\" else x)\n",
    "    df[\"opening_weekend_gross_currency\"] = df[\"opening_weekend_gross_currency\"].replace(\"$\", \"USD\")\n",
    "    df[\"opening_weekend_gross_currency\"] = df[\"opening_weekend_gross_currency\"].replace(\"£\", \"GBP\")\n",
    "    df[\"opening_weekend_gross_currency\"] = df[\"opening_weekend_gross_currency\"].replace(\"€\", \"EUR\")\n",
    "    df[\"opening_weekend_gross_currency\"] = df[\"opening_weekend_gross_currency\"].replace(\"€.\", \"EUR\")\n",
    "    df[\"opening_weekend_gross_USD\"] = df[\"opening_weekend_gross\"].apply(lambda x: float(x[1:].split()[-1]) \\\n",
    "                                                                        if x != \"\" else x)\n",
    "    df[\"opening_weekend_gross_USD\"] = df.apply(lambda x: convert_to_USD( \\\n",
    "                                               x[\"opening_weekend_gross_USD\"], x[\"opening_weekend_gross_currency\"]) \\\n",
    "                                               if (x[\"opening_weekend_gross_USD\"] != \"\") and \\\n",
    "                                               (x[\"opening_weekend_gross_currency\"] != \"\") else \"\", axis=1)\n",
    "    \n",
    "    # Color\n",
    "    df[\"color\"] = df[\"color\"].apply(lambda x: extract_color(x))\n",
    "    \n",
    "    # Aspect ratio\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\"x\", \":\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: \"!!!!!\" if (\":\" not in x) and (x != \"\") else x)\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: re.sub(r\"[a-zA-Z]\", \"\", x))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\",\", \".\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\"2:35\", \"2.35\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\" : \", \":\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\"4: 3\", \"4:3\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\"16: 9\", \":\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.split()[0] if x != \"\" else x)\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.strip(\":\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\":\", \"/\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: x.replace(\"!!!!!\", \"Other\"))\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].apply(lambda x: eval_division_string(x) \\\n",
    "                                                  if (x != \"\" and x != \"Other\") else x)\n",
    "    df[\"aspect_ratio\"] = df[\"aspect_ratio\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_in_nominees_and_wins(df, nom_win_df):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    df = Pandas dataframe of cleaned and processed movie data from IMDB index list pages\n",
    "    nom_win_df = Pandas dataframe of cleaned and processed Best Picture status data from Wikipedia\n",
    "    \n",
    "    Out:\n",
    "    new_df = Merged pandas data frame now including both the original movie data and Best Picture status\n",
    "    \"\"\"\n",
    "    nom_win_for_merge = nom_win_df[nom_win_df[\"year\"].astype(int) >= 1990]\n",
    "    nom_win_for_merge = nom_win_for_merge[[\"key\", \"status\", \"status_year\"]]\n",
    "    \n",
    "    new_df = pd.merge(df, nom_win_for_merge, on=\"key\", how=\"left\")\n",
    "\n",
    "    new_df[\"status\"][10186] = np.nan\n",
    "    new_df[\"status_year\"][10186] = np.nan\n",
    "    new_df[\"status\"][57111] = np.nan\n",
    "    new_df[\"status_year\"][57111] = np.nan\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_in_detailed_movie_data(df, detailed_df):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    df = Merged pandas data frame including both the original movie data and Best Picture status\n",
    "    detailed_df = Pandas dataframe of cleaned and processed detailed movie data from IMDB individual movie pages\n",
    "    \n",
    "    Out:\n",
    "    new_df = Merged pandas dataframe now including original movie data, detailed movie data, and Best Picture status\n",
    "    \"\"\"\n",
    "    new_df = pd.merge(df, detailed_df, on=\"link\", how=\"left\")\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in raw scraped data\n",
    "movie_data = load_pickle(\"movie_data.pkl\")\n",
    "nominees_and_winners_raw = load_pickle(\"nominees_and_winners.pkl\")\n",
    "detailed_movie_data = load_pickle(\"detailed_movie_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process the data\n",
    "df = process_IMDB_data(movie_data)\n",
    "nom_win_df = process_nominee_and_winner_data(nominees_and_winners_raw)\n",
    "detailed_df = process_detailed_movie_data(detailed_movie_data)\n",
    "\n",
    "df = merge_in_nominees_and_wins(df, nom_win_df)\n",
    "df = merge_in_detailed_movie_data(df, detailed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Get the list of links used to scrape the raw detailed movie data (if needed)\"\"\"\n",
    "# links = df[\"link\"].values\n",
    "# pickle_it(links, \"all_links.pkl\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_inflation_multipliers():\n",
    "    \"\"\"\n",
    "    In:\n",
    "    None\n",
    "    \n",
    "    Out:\n",
    "    Returns a dictionary with multipliers to adjust for inflation for each year 1990 - 2014\n",
    "    \"\"\"\n",
    "    \n",
    "    inflation_rates = [\"5.4\", \"4.2\", \"3\", \"3\", \"2.6\", \"2.8\", \"3\", \"2.3\", \"1.6\", \"2.2\", \"3.4\", \"2.8\", \"1.6\", \"2.3\", \\\n",
    "                       \"2.7\", \"3.4\", \"3.2\", \"2.8\", \"3.8\", \"-0.4\", \"1.6\", \"3.2\", \"2.1\", \"1.5\", \"1.6\"]\n",
    "    inflation_rates = sorted(list(zip(range(1990, 2015), inflation_rates)), reverse=True)\n",
    "    inflation_rates = [(y, float(rate)/100 + 1) for y, rate in inflation_rates]\n",
    "    \n",
    "    inflation_multipliers = {}\n",
    "    for year, rate in inflation_rates:\n",
    "        inflation_multiple = 1\n",
    "        for year, rate in inflation_rates[:(2015-year)]:\n",
    "            inflation_multiple *= rate\n",
    "        inflation_multipliers[year] = inflation_multiple\n",
    "    \n",
    "    return inflation_multipliers\n",
    "\n",
    "inflation_multipliers = get_inflation_multipliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def final_clean(df):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    df = Merged pandas dataframe including original movie data, detailed movie data, and Best Picture status\n",
    "    \n",
    "    Out:\n",
    "    df = Merged pandas dataframe with additional (final) cleaning and processing\n",
    "    \"\"\"\n",
    "    # Parental Guidance (MPAA) Rating\n",
    "    df = df[df[\"pg_rating\"] != \"APPROVED\"]\n",
    "    df[\"pg_rating\"] = df[\"pg_rating\"].replace(\"X\", \"NC_17\")\n",
    "    df[\"pg_rating\"] = df[\"pg_rating\"].replace(\"NOT_RATED\", \"UNRATED\")\n",
    "    df[\"pg_rating\"] = df[\"pg_rating\"].replace(\"\", \"UNRATED\")\n",
    "\n",
    "    # Status and Status Score\n",
    "    df[\"status_score\"] = df[\"status\"]\n",
    "    df[\"status_score\"] = df[\"status_score\"].replace(\"W\", 10)\n",
    "    df[\"status_score\"] = df[\"status_score\"].replace(\"N\", 5)\n",
    "    df[\"status_score\"] = df[\"status_score\"].replace(np.nan, 0)\n",
    "    \n",
    "    # Status Year\n",
    "    df[\"status_year\"].fillna(df[\"year\"], inplace=True)\n",
    "    \n",
    "    # Number Nominees\n",
    "    df[\"num_nominees\"] = df[\"status_year\"].apply(lambda x: \"5\" if int(x) <= 2008 else \">5\")\n",
    "    \n",
    "    # Budget\n",
    "    df[\"budget_USD_real\"] = df.apply(lambda x: x[\"budget_USD\"] * inflation_multipliers[int(x[\"year\"])] \\\n",
    "                                     if x[\"budget_USD\"] != \"\" else x[\"budget_USD\"], axis=1)\n",
    "    df[\"budget_USD_real\"] = df[\"budget_USD_real\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # Opening Weekend Gross\n",
    "    df[\"opening_weekend_gross_USD_real\"] = df.apply(lambda x: x[\"opening_weekend_gross_USD\"] * \\\n",
    "                                                    inflation_multipliers[int(x[\"year\"])] \\\n",
    "                                                    if x[\"opening_weekend_gross_USD\"] != \"\" \\\n",
    "                                                    else x[\"opening_weekend_gross_USD\"], axis=1)\n",
    "    df[\"opening_weekend_gross_USD_real\"] = df[\"opening_weekend_gross_USD_real\"].convert_objects(convert_numeric=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = final_clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loads lists of directors, actors, actresses, writers\n",
    "directors, actors, actresses = load_pickle(\"directors_actors_actresses.pkl\")\n",
    "stars = actors + actresses\n",
    "writers = load_pickle(\"writers.pkl\")\n",
    "\n",
    "# Make list of genre to use as possible regression features\n",
    "genres = sorted(list(set([genre for genre_list in df[\"genre\"].values for genre in genre_list]))[1:])\n",
    "genres_to_exclude = [\"News\", \"Talk-Show\", \"Game-Show\", \"Reality-TV\", \"Documentary\", \"Adult\"]\n",
    "genres = [genre for genre in genres if genre not in genres_to_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_hist_dict(df, column):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    df = Merged pandas dataframe with final cleaning complete\n",
    "    column = Data column to make histogram / counter dictionary for\n",
    "    \n",
    "    Out:\n",
    "    d = Histogram / counter dictionary of number occurances of each key in the data set\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for lst in df[column].values:\n",
    "        for x in lst:\n",
    "            d[x] = d.get(x, 0) + 1\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make list of countries to use as possible regression features\n",
    "country_hist = make_hist_dict(detailed_df, \"country\")\n",
    "countries = list(country_hist.items())\n",
    "countries = sorted(countries, key=lambda x: x[1])[-25:]  # Take top 25\n",
    "countries = [x[0] for x in countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make list of countries to use as possible regression features\n",
    "language_hist = make_hist_dict(detailed_df, \"language\")\n",
    "languages = list(language_hist.items())\n",
    "languages = sorted(languages, key=lambda x: x[1])[-25:]  # Take top 25\n",
    "languages = [x[0] for x in languages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_boolean_columns(df, old_column, new_columns):\n",
    "    \"\"\"\n",
    "    In:\n",
    "    df = Merged pandas dataframe with final cleaning complete\n",
    "    old_column = column of interest in df with data points that are list of items (e.g. \"Directors\" or \"Starring\")\n",
    "    new_columns = list of columns to make as a boolean column (e.g. for \"Directors\" this would be a list of \n",
    "                  individual directors)\n",
    "    \n",
    "    Out:\n",
    "    df = Merged pandas dataframe with final cleaning complete and the desired boolean columns added\n",
    "    \"\"\"\n",
    "    for column in new_columns:\n",
    "        column_name = old_column + \"_\"\n",
    "        column_name += column.lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\".\", \"\")\n",
    "        df[column_name] = df[old_column].apply(lambda x: 1 if column in x else 0)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make all the boolean columns\n",
    "df = make_boolean_columns(df, \"director\", directors)\n",
    "df = make_boolean_columns(df, \"starring\", stars)\n",
    "df = make_boolean_columns(df, \"genre\", genres)\n",
    "df = make_boolean_columns(df, \"writer\", writers)\n",
    "df = make_boolean_columns(df, \"country\", countries)\n",
    "df = make_boolean_columns(df, \"language\", languages)\n",
    "df = make_boolean_columns(df, \"color\", [\"Color\", \"Black and White\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of columns not needed regression\n",
    "df = df.drop([\"title\", \"year\", \"user_rating_n\", \"director\", \"starring\", \"genre\", \"link\", \"status\", \"release_date\", \\\n",
    "              \"critic_rating_n\", \"writer\", \"country\", \"language\", \"budget\", \"budget\", \"opening_weekend_gross\", \\\n",
    "              \"production_company\", \"sound_mix\", \"color\", \"release_date_details\", \"release_date_datetime\", \\\n",
    "              \"budget_currency\", \"budget_USD\", \"opening_weekend_gross_currency\", \"opening_weekend_gross_USD\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Uncomment this when you want to save the final dataframe you will you use for regression\"\"\"\n",
    "# pickle_it(df, \"df_for_regression.pkl\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
